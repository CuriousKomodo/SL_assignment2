{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import scipy\n",
    "import scipy.io as spio\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "import urllib\n",
    "from urllib.request import urlopen\n",
    "%matplotlib inline\n",
    "import urllib.request\n",
    "import datetime as dt\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_data(m,n):\n",
    "    data = np.random.uniform(low=-1, high=1, size=(m,(n+1)))\n",
    "    data = np.sign(data)\n",
    "    return data\n",
    "\n",
    "def generate_data_winnow(m,n):\n",
    "    data = np.random.randint(2, size=(m,(n+1)))\n",
    "    data = np.sign(data)\n",
    "    return data\n",
    "\n",
    "def add_bias(x):\n",
    "    x_with_bias = np.ones((x.shape[0],x.shape[1]+1))\n",
    "    x_with_bias[:,:-1] = x\n",
    "    return x_with_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = generate_data(4,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1., -1., -1.,  1.],\n",
       "       [ 1.,  1.,  1., -1.],\n",
       "       [ 1.,  1., -1.,  1.],\n",
       "       [-1.,  1.,  1., -1.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary perceptron algorithm \n",
    "# Learning rate? \n",
    "def perceptron_train(x,y,max_epoch=20, tol=0.01, learning_rate=1,random_select=False):\n",
    "    m = x.shape[0] #number of examples\n",
    "    n = x.shape[1] #number of features\n",
    "    #x = add_bias(x)\n",
    "    error_per_epoch = np.zeros(max_epoch)\n",
    "    errors = np.zeros(m)\n",
    "    W = np.zeros(n+1)\n",
    "    \n",
    "    num_errors = 0 \n",
    "    \n",
    "    if random_select:\n",
    "        max_epoch =1\n",
    "        m = np.random.randint(m) #select random number of\n",
    "    \n",
    "    for epoch in range(max_epoch):\n",
    "        #print('epoch=',epoch)\n",
    "        errors = np.zeros(m)\n",
    "        num_errors = 0 #This should be bounded..? Maybe calculate the bound in the explanation\n",
    "    \n",
    "        #iterate through training set\n",
    "        for t in range(m):\n",
    "            x_t = x[t,:]\n",
    "            y_t = y[t]\n",
    "            pred_t = np.sign(W@x_t) #0 to begin with \n",
    "    \n",
    "            if pred_t*y_t<=0:\n",
    "                #print('t=',t)\n",
    "                #print('error! y_lab=', y_t)\n",
    "                num_errors +=1\n",
    "                W = W + learning_rate*x_t.T*y_t\n",
    "                errors[t] = num_errors \n",
    "                #print('W=',W)\n",
    "                \n",
    "        error_per_epoch[epoch] = num_errors\n",
    "        #print(epoch, 'error=',errors[-1])\n",
    "        \n",
    "        #print('current_error_rate', error_per_epoch)\n",
    "        \n",
    "        if epoch>1:\n",
    "            #print('old_error=',error_per_epoch[epoch-1])\n",
    "            #print('new_error=',error_per_epoch[epoch])\n",
    "            diff_rates = (error_per_epoch[epoch-1] - error_per_epoch[epoch])/m\n",
    " \n",
    "            #Stop if the error rate has increased, \n",
    "            #or the difference in error rate between the previous one and the current one < tolerance. \n",
    "            if error_per_epoch[epoch]/m < 0.05:\n",
    "                print('error rate< 10%')\n",
    "                if diff_rates<tol:\n",
    "                    print('converging')\n",
    "                elif diff_rates<0:\n",
    "                    print('error increased')\n",
    "                elif error_per_epoch[epoch]==0:\n",
    "                    print('no error')\n",
    "                    break\n",
    "        \n",
    "    return W, error_per_epoch[:epoch+1]\n",
    "\n",
    "\n",
    "def perceptron_test(x_test,y_test,W):\n",
    "    x_test = add_bias(x_test)\n",
    "    m_test = x_test.shape[0]\n",
    "    pred = np.sign(x_test@W) #(n,1) x (m_test,n)\n",
    "    diff = pred - y_test\n",
    "    mistakes = len(diff[diff!=0])   \n",
    "    return mistakes,pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error rate< 10%\n",
      "error rate< 10%\n",
      "no error\n"
     ]
    }
   ],
   "source": [
    "df = generate_data(40,30)\n",
    "x = df[:,:]\n",
    "y = df[:,0]\n",
    "W, error_per_epoch = perceptron_train(x,y,max_epoch=30, tol=0.01, learning_rate=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "mistakes,pred = perceptron_test(x[:10],y[:10],W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([28., 19., 15., 14., 11.,  8., 11.,  8., 14.,  7.,  7.,  8.,  7.,\n",
       "        5.,  8.,  6.,  3.,  7.,  0.])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_per_epoch\n",
    "### Does not seem to converge for some combination of x and y. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Winnow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def winnow_train(x,y,max_epoch=20,tol=0.01, learning_rate=1,gamma_bound=0.5):\n",
    "    m = x.shape[0] #number of examples\n",
    "    n = x.shape[1] #number of features\n",
    "    error_per_epoch = np.zeros(max_epoch)\n",
    "    errors = np.zeros(m)\n",
    "    W = np.ones(n)\n",
    "    mistake_bound = (n/gamma_bound)**2\n",
    "    gamma_bound = n/2\n",
    "    num_errors = 0 \n",
    "    \n",
    "    #for epoch in range(max_epoch):\n",
    "    epoch = 0\n",
    "    while epoch < max_epoch:   \n",
    "        errors = np.zeros(m)\n",
    "        num_errors = 0 #This should be bounded..? Maybe calculate the bound in the explanation\n",
    "        print('epoch=',epoch)\n",
    "        #iterate through training set\n",
    "        for t in range(m):\n",
    "            \n",
    "            x_t = x[t,:]\n",
    "            y_t = y[t]\n",
    "            gamma = W@x_t\n",
    "            \n",
    "            if gamma>= gamma_bound:\n",
    "                pred_t = 1\n",
    "            else:\n",
    "                pred_t = 0\n",
    "            \n",
    "            if pred_t != y_t:\n",
    "#                 print('error!')\n",
    "                #print('pred=',pred_t)\n",
    "#                 print('y_t=',y_t)\n",
    "                num_errors+=1\n",
    "                print('x_t=',x_t)\n",
    "                print('y_t=',y_t)\n",
    "                power = (y_t - pred_t)*x_t/1.0 #1 when error made on positive class, -1 when error made on negative class\n",
    "                print('ratio of update of W',power)\n",
    "                W = W*(2**power) #element wise multiplication, and element wise power\n",
    "                print('W=',W)\n",
    "                #Once weight>n, it should no longer change. \n",
    "                W[W>n] = n\n",
    "#                 print(W)\n",
    "                errors[t] = num_errors\n",
    "#                 print('current error',num_errors)\n",
    "                #print('W=',W)\n",
    "                \n",
    "        error_per_epoch[epoch] = num_errors\n",
    "        \n",
    "        if epoch>1:\n",
    "            diff_rates = (error_per_epoch[epoch-1] - error_per_epoch[epoch])/m\n",
    "            print(\"Error rate is now \", error_per_epoch[epoch]/m )\n",
    "            #Stop if the error rate has increased, \n",
    "            #or the difference in error rate between the previous one and the current one < tolerance. \n",
    "            if error_per_epoch[epoch]/m < 0.05:\n",
    "                print('error rate< 5%')\n",
    "                if diff_rates<tol:\n",
    "                    print('converging')\n",
    "                elif diff_rates<0:\n",
    "                    print('error increased')\n",
    "                elif error_per_epoch[epoch]==0:\n",
    "                    print('no error')\n",
    "                    \n",
    "                break\n",
    "        epoch += 1\n",
    "    return W, error_per_epoch[:epoch+1]\n",
    "\n",
    "\n",
    "def winnow_test(x_test,y_test,W,gamma=0):\n",
    "    m_test = x_test.shape[0]\n",
    "    gamma = W@x_t\n",
    "    if gamma>=n:\n",
    "        pred_t = 1\n",
    "    else:\n",
    "        pred_t = -1\n",
    "    diff = pred - y_test\n",
    "    mistakes = len(diff[diff!=0])  \n",
    "    return mistakes,pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch= 0\n",
      "x_t= [0 1 1]\n",
      "y_t= 0\n",
      "ratio of update of W [ 0. -1. -1.]\n",
      "W= [1.  0.5 0.5]\n",
      "x_t= [1 0 0]\n",
      "y_t= 1\n",
      "ratio of update of W [1. 0. 0.]\n",
      "W= [2.  0.5 0.5]\n",
      "epoch= 1\n",
      "epoch= 2\n",
      "Error rate is now  0.0\n",
      "error rate< 5%\n",
      "converging\n"
     ]
    }
   ],
   "source": [
    "df = generate_data_winnow(40,2)\n",
    "x = df\n",
    "y = df[:,0]\n",
    "W, error_per_epoch = winnow_train(x,y,max_epoch=15,tol=0.01, learning_rate=1,gamma_bound=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 0., 0.])"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.95312500e-03, 1.00000000e+00, 5.00000000e-01, 1.00000000e+00,\n",
       "       9.76562500e-04, 2.00000000e+00, 4.88281250e-04, 4.88281250e-04,\n",
       "       1.56250000e-02, 1.00000000e+00, 2.50000000e-01, 4.76837158e-07,\n",
       "       7.81250000e-03, 3.12500000e-02, 1.56250000e-02, 1.52587891e-05,\n",
       "       2.50000000e-01, 1.25000000e-01, 4.00000000e+00, 2.50000000e-01,\n",
       "       6.10351562e-05, 2.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 6.25000000e-02, 3.12500000e-02, 1.25000000e-01,\n",
       "       9.76562500e-04, 1.56250000e-02])"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Least Squares Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1 Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
