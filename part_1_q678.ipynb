{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternative Approaches to Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import scipy\n",
    "import scipy.io as spio\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "import urllib\n",
    "from urllib.request import urlopen\n",
    "%matplotlib inline\n",
    "import urllib.request\n",
    "import datetime as dt\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "link = \"http://www0.cs.ucl.ac.uk/staff/M.Herbster/SL/misc/zipcombo.dat\"\n",
    "filename = 'zipcombo.dat'\n",
    "urllib.request.urlretrieve(link, filename)\n",
    "data = np.loadtxt(filename)     # read numpy array from fil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = data[:,0]\n",
    "x = data[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q6 - Alternative generalization method, One vs. One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def allocate_training_test_sets(data,r =1/5):\n",
    "    X= data[:,1:]\n",
    "    y= data[:,0]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=r)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def add_bias(x):\n",
    "    x_with_bias = np.ones((x.shape[0],x.shape[1]+1))\n",
    "    x_with_bias[:,:-1] = x\n",
    "    return x_with_bias\n",
    "\n",
    "#Discuss the use of the this kernel. i.e. talk about non-linear seperability. \n",
    "def Polynomial_Kernel(x1,x2,d):\n",
    "    K = (x1 @ x2.T)**d\n",
    "    return K\n",
    "\n",
    "def pairwise_distance_single(X): # distances of X training data, single X matrix\n",
    "    m =X.shape[0]\n",
    "    n = X.shape[1]\n",
    "    G = np.matmul(X,X.T)\n",
    "    DG = np.diag(G).reshape(G.shape[0],1)\n",
    "    distances_sq = np.matmul(DG,np.ones((G.shape[0],1)).T)+ np.matmul(np.ones((G.shape[1],1)),DG.T)-2.0*G\n",
    "    return distances_sq\n",
    "\n",
    "def pairwise_distance_double(X1,X2): # distances of X training data, double matrices, X1 and X2\n",
    "    X1_pow = (X1**2).sum(axis=1).reshape(X1.shape[0],1) #sum the rows, size m1 array\n",
    "    X2_pow = (X2**2).sum(axis=1).reshape(X2.shape[0],1) #sum the rows, size m2 array\n",
    "    G = np.matmul(X1,X2.T)\n",
    "    m1,m2 =G.shape[0],G.shape[1] \n",
    "    distances_sq = np.matmul(X1_pow,np.ones((m2,1)).T)+ np.matmul(np.ones((m1,1)),X2_pow.T)-2.0*G\n",
    "    return distances_sq\n",
    "\n",
    "def Gaussian_Kernel(distances_sq,c=1):\n",
    "    K = np.exp(-c*distances_sq)\n",
    "    return K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One vs. One Pairwise Multiclass Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#One vs. one approach: train k*(k-1)/2 binary classifiers to identify k classes\n",
    "#For example, one classifier could be trained to distinguish between digit 0 and digit 1.\n",
    "#Consider symmetry when computing prediction\n",
    "\n",
    "#Write a function that trains a binary classifier given two classes, given kernel:\n",
    "def classifier_ovo(class1,class2,K,alpha_ovo,w,iter_num):\n",
    "    m = x.shape[0] #number of examples\n",
    "    n = x.shape[1] #number of features\n",
    "    vote = np.sign(((alpha_ovo[:iter_num].T @K[iter_num,:iter_num]).T))\n",
    "    return vote #returns a vote, within (-1,1)\n",
    "\n",
    "\n",
    "def perceptron_train_ovo(x,y,d=2,kernel_choice='Polynomial'):\n",
    "    m = x.shape[0] #number of examples\n",
    "    n = x.shape[1] #number of features\n",
    "    classes_num = 10 #number of classes \n",
    "    \n",
    "    errors = np.zeros(m)\n",
    "    \n",
    "    if kernel_choice=='Polynomial':\n",
    "        K_train = Polynomial_Kernel(x,x,d)\n",
    "    elif kernel_choice=='Gaussian':\n",
    "        pairwise_distances = pairwise_distance_single(x)\n",
    "        K_train = Gaussian_Kernel(pairwise_distances,c=d)\n",
    "    \n",
    "    num_errors = 0 #This should be bounded..? Maybe calculate the bound in the explanation\n",
    "    W = np.zeros((m,classes_num,classes_num)) #with bias?\n",
    "    alpha = np.zeros((m,classes_num,classes_num)) \n",
    "    \n",
    "    \n",
    "    #iterate through training set\n",
    "    for t in range(m):\n",
    "        if t<1:\n",
    "            alpha_prev = np.zeros((1,classes_num,classes_num)) #when t=0, the previous alpha is set to be 0\n",
    "        else:\n",
    "            alpha_prev = alpha[t-1,:,:] #\n",
    "        \n",
    "        \n",
    "        #find our training set\n",
    "        x_t = x[t,:]\n",
    "        y_t = y[t]\n",
    "        #y_arr_t = y_arr[t,:] #of size (1,10) \n",
    "        \n",
    "        votes_board = np.zeros((classes_num, classes_num)) #zero on the horizontal. \n",
    "        classes_list = np.array(range(classes_num))\n",
    "        \n",
    "       \n",
    "        for i in range(classes_num):\n",
    "            c1 = classes_list[i]\n",
    "            classes_rest = classes_list[classes_list>c1]\n",
    "            for j in range(len(classes_rest)):\n",
    "                c2 = classes_rest[j]\n",
    "                w = W[:,int(c1),int(c2)]\n",
    "                alpha_ovo = alpha[:,int(c1),int(c2)]\n",
    "                vote = classifier_ovo(c1,c2,K_train,alpha_ovo,w,iter_num=t) #vote in {-1,1}\n",
    "                votes_board[int(c1),int(c2)] = vote\n",
    "                \n",
    "                \n",
    "        #Count the votes in the board\n",
    "        votes_count = votes_board.sum(axis=0)\n",
    "        pred_t = votes_count.argmax()\n",
    "        \n",
    "        #if t%10000==0:\n",
    "            \n",
    "            #print('t=',t)\n",
    "            #print('label=', y_t)\n",
    "            #print('predicted label=',pred_t)\n",
    "        \n",
    "        \n",
    "        if pred_t!=y_t:\n",
    "            #print('misclassification:')\n",
    "            #update the alpha, and weights, for all the classes that not the true class\n",
    "            num_errors +=1\n",
    "            \n",
    "            #increase alpha for all the positive classifier of the correct label.\n",
    "            #decrease alpha for the negative classifier of the false label. \n",
    "            alpha_t = np.zeros((classes_num,classes_num)) #initialize to a 10 x 10 zero matrix\n",
    "            #alpha_t[int(y_t),:] =+1\n",
    "            #alpha_t[int(pred_t),:] =-1\n",
    "            alpha_t[:,int(y_t)] =+1 # column belonging to correct label class +=1\n",
    "            alpha_t[:,int(pred_t)] =-1 # column belonging to false predicted class -=1\n",
    "            \n",
    "            #store alpha_t into the matrix for future reference\n",
    "            alpha[t,:,:] = alpha_t\n",
    "            \n",
    "            #sandwich K(x_t, x_i) for i in [1,t-1] in a zeros array of size(m). \n",
    "            #reason being weight for one class is of size(m), but we only 'have enough data' to update the first t-1 terms.  \n",
    "            K_update = np.zeros((1,m))\n",
    "            K_update[:,:t] = K_train[t,:t] \n",
    "            \n",
    "            #Note that W is a weight matrix of size (m, 10)\n",
    "            #K_update.T @alpha_t is the update for weight matrix, for every class and every training set that has been reviewed. \n",
    "            W_update = K_update.T @(alpha_t.reshape(1,100)) \n",
    "            \n",
    "            W = W+ W_update.reshape(W.shape) #(1, 10) * (1,m), want (m,10)\n",
    "        else:\n",
    "            W = W #no change\n",
    "            \n",
    "        errors[t] = num_errors         \n",
    "    return W,alpha, errors\n",
    "\n",
    "\n",
    "def perceptron_test_ovo(x_test,x_train,y_test,W, alphas, d,kernel_choice='Polynomial'):\n",
    "    m_test = x_test.shape[0]\n",
    "    m_train = x_train.shape[0]\n",
    "    \n",
    "    if kernel_choice=='Polynomial':\n",
    "        K_test = Polynomial_Kernel(x_train, x_test, d)\n",
    "    elif kernel_choice=='Gaussian':\n",
    "        pairwise_distances = pairwise_distance_double(x_train,x_test,d)\n",
    "        K_test = Gaussian_Kernel(pairwise_distances,c=d)\n",
    "    \n",
    "    classes_num = 10\n",
    "    classes_list = np.array(range(classes_num))\n",
    "    votes_ovo =np.zeros((m_test,10,10))\n",
    "    \n",
    "    for i in range(classes_num):\n",
    "        c1 = classes_list[i]\n",
    "        classes_rest = classes_list[classes_list>c1]\n",
    "        for j in range(len(classes_rest)):\n",
    "            c2 = classes_rest[j]\n",
    "            alphas_ovo_c1c2 = alphas[:,int(c1),int(c2)]\n",
    "            vote = np.sign(alphas_ovo_c1c2.T@K_test) \n",
    "            votes_ovo[:,c1,c2] = vote\n",
    "                \n",
    "    sum_votes = np.sum(votes_ovo,axis=1)\n",
    "    pred = sum_votes.argmax(axis=1)\n",
    "    \n",
    "    diff = pred - y_test\n",
    "    mistakes = len(diff[diff!=0])\n",
    "    return pred,mistakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Cross Validation of One vs. One\n",
    "def cross_validation_ovo(matrix,d_values,k=5,kernel_choice='Polynomial'):\n",
    "    #np.random.shuffle(matrix)\n",
    "    kf = KFold(n_splits=k)\n",
    "    error_cv_arr = np.zeros(k)\n",
    "    \n",
    "    for train_index, cv_index in kf.split(matrix):\n",
    "        # Spit the matrix using the indices gained by the CV method and construct X and Y arrays\n",
    "        matrix_train, matrix_cv = matrix[train_index], matrix[cv_index]\n",
    "\n",
    "        X_train = matrix_train[:,0:-1]\n",
    "        X_cv = matrix_cv[:,0:-1]\n",
    "        y_train = matrix_train[:,-1] \n",
    "        y_cv = matrix_cv[:,-1]\n",
    "\n",
    "        # We are only interested in the alphas and not the MSE on the training set\n",
    "        W, alphas, train_errors = perceptron_train_ovo(X_train,y_train, d)\n",
    "        predictions, test_errors = perceptron_test_ovo(X_cv, X_train, y_cv, W, alphas, d)\n",
    "        error_cv_arrr[i] = test_errors\n",
    "        i += 1\n",
    "        \n",
    "        return error_cv_arr.mean(), (error_cv_arr.var())**(1/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment on all training data and test data, d=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.557675\n"
     ]
    }
   ],
   "source": [
    "startTime = datetime.now()\n",
    "X_train, X_test, y_train, y_test = allocate_training_test_sets(data,r =1/5)\n",
    "W_ovo, alphas_ovo, train_errors = perceptron_train_ovo(X_train,y_train, 2)\n",
    "predictions, test_errors = perceptron_test_ovo(X_test, X_train, y_test, W_ovo, alphas_ovo, 2)\n",
    "print(datetime.now() - startTime )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9182795698924731"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = 1-test_errors/y_test.shape[0]\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a2692f470>]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_errors/np.arange(1,X_train.shape[0]+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Results  - Polynomial Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken:  0:00:17.346310d= 1 .........\n",
      "Time taken:  0:00:16.929518d= 1 .........\n",
      "Time taken:  0:00:15.105453d= 1 .........\n",
      "Time taken:  0:00:15.142342d= 1 .........\n",
      "Time taken:  0:00:14.997456d= 1 .........\n",
      "Time taken:  0:00:14.944090d= 1 .........\n",
      "Time taken:  0:00:14.938723d= 1 .........\n",
      "Time taken:  0:00:15.663484d= 1 .........\n",
      "Time taken:  0:00:14.924983d= 1 .........\n",
      "Time taken:  0:00:15.286689d= 1 .........\n",
      "Time taken:  0:00:15.388302 d= 1 .........\n",
      "Time taken:  0:00:15.327316 d= 1 .........\n",
      "Time taken:  0:00:14.925340 d= 1 .........\n",
      "Time taken:  0:00:15.190213 d= 1 .........\n",
      "Time taken:  0:00:14.790795 d= 1 .........\n",
      "Time taken:  0:00:15.708110 d= 1 .........\n",
      "Time taken:  0:00:15.173589 d= 1 .........\n",
      "Time taken:  0:00:15.316084 d= 1 .........\n",
      "Time taken:  0:00:14.994880 d= 1 .........\n",
      "Time taken:  0:00:14.862597 d= 1 .........\n",
      "Time taken:  0:00:12.396770d= 2 .........\n",
      "Time taken:  0:00:12.295094d= 2 .........\n",
      "Time taken:  0:00:12.672932d= 2 .........\n",
      "Time taken:  0:00:12.666945d= 2 .........\n",
      "Time taken:  0:00:12.394911d= 2 .........\n",
      "Time taken:  0:00:12.587266d= 2 .........\n",
      "Time taken:  0:00:12.567647d= 2 .........\n",
      "Time taken:  0:00:12.233615d= 2 .........\n",
      "Time taken:  0:00:12.361986d= 2 .........\n",
      "Time taken:  0:00:12.391049d= 2 .........\n",
      "Time taken:  0:00:12.223607 d= 2 .........\n",
      "Time taken:  0:00:12.276580 d= 2 .........\n",
      "Time taken:  0:00:12.281099 d= 2 .........\n",
      "Time taken:  0:00:12.938471 d= 2 .........\n",
      "Time taken:  0:00:12.404879 d= 2 .........\n",
      "Time taken:  0:00:12.334158 d= 2 .........\n",
      "Time taken:  0:00:12.367161 d= 2 .........\n",
      "Time taken:  0:00:12.383999 d= 2 .........\n",
      "Time taken:  0:00:12.202887 d= 2 .........\n",
      "Time taken:  0:00:12.154337 d= 2 .........\n",
      "Time taken:  0:00:13.734676d= 3 .........\n",
      "Time taken:  0:00:13.758451d= 3 .........\n",
      "Time taken:  0:00:14.004821d= 3 .........\n",
      "Time taken:  0:00:13.577088d= 3 .........\n",
      "Time taken:  0:00:13.279039d= 3 .........\n",
      "Time taken:  0:00:13.359181d= 3 .........\n",
      "Time taken:  0:00:13.986679d= 3 .........\n",
      "Time taken:  0:14:01.322582d= 3 .........\n",
      "Time taken:  0:00:26.072837d= 3 .........\n",
      "Time taken:  0:00:23.575860d= 3 .........\n",
      "Time taken:  0:00:24.522214 d= 3 .........\n",
      "Time taken:  0:00:24.184318 d= 3 .........\n",
      "Time taken:  0:00:19.707854 d= 3 .........\n",
      "Time taken:  0:00:20.270231 d= 3 .........\n",
      "Time taken:  0:00:18.852037 d= 3 .........\n",
      "Time taken:  0:00:26.468049 d= 3 .........\n",
      "Time taken:  0:00:23.134429 d= 3 .........\n",
      "Time taken:  0:00:20.149907 d= 3 .........\n",
      "Time taken:  0:00:20.201203 d= 3 .........\n",
      "Time taken:  0:00:20.290701 d= 3 .........\n",
      "Time taken:  0:00:19.855141d= 4 .........\n",
      "Time taken:  0:00:21.262354d= 4 .........\n",
      "Time taken:  0:00:19.787681d= 4 .........\n",
      "Time taken:  0:00:19.630075d= 4 .........\n",
      "Time taken:  0:00:19.306823d= 4 .........\n",
      "Time taken:  0:00:19.661003d= 4 .........\n",
      "Time taken:  0:00:19.973723d= 4 .........\n",
      "Time taken:  0:00:21.091697d= 4 .........\n",
      "Time taken:  0:00:19.580534d= 4 .........\n",
      "Time taken:  0:00:19.262342d= 4 .........\n",
      "Time taken:  0:00:19.403945 d= 4 .........\n",
      "Time taken:  0:00:19.623500 d= 4 .........\n",
      "Time taken:  0:00:20.463054 d= 4 .........\n",
      "Time taken:  0:00:22.101830 d= 4 .........\n",
      "Time taken:  0:00:20.737975 d= 4 .........\n",
      "Time taken:  0:00:19.958378 d= 4 .........\n",
      "Time taken:  0:00:20.423108 d= 4 .........\n",
      "Time taken:  0:00:20.885447 d= 4 .........\n",
      "Time taken:  0:00:14.840178 d= 4 .........\n",
      "Time taken:  0:00:13.710117 d= 4 .........\n",
      "Time taken:  0:00:13.291336d= 5 .........\n",
      "Time taken:  0:00:13.061562d= 5 .........\n",
      "Time taken:  0:00:13.259625d= 5 .........\n",
      "Time taken:  0:00:12.943568d= 5 .........\n",
      "Time taken:  0:00:13.082025d= 5 .........\n",
      "Time taken:  0:00:14.346314d= 5 .........\n",
      "Time taken:  0:00:21.176944d= 5 .........\n",
      "Time taken:  0:00:20.249286d= 5 .........\n",
      "Time taken:  0:00:19.720364d= 5 .........\n",
      "Time taken:  0:00:19.765556d= 5 .........\n",
      "Time taken:  0:00:18.819696 d= 5 .........\n",
      "Time taken:  0:00:19.031689 d= 5 .........\n",
      "Time taken:  0:00:19.405041 d= 5 .........\n",
      "Time taken:  0:00:20.044700 d= 5 .........\n",
      "Time taken:  0:00:19.602159 d= 5 .........\n",
      "Time taken:  0:00:22.803905 d= 5 .........\n",
      "Time taken:  0:00:18.546151 d= 5 .........\n",
      "Time taken:  0:00:15.804749 d= 5 .........\n",
      "Time taken:  0:00:21.696181 d= 5 .........\n",
      "Time taken:  0:00:19.580701 d= 5 .........\n",
      "Time taken:  0:00:20.417297d= 6 .........\n",
      "Time taken:  0:00:19.972931d= 6 .........\n",
      "Time taken:  0:00:18.993693d= 6 .........\n",
      "Time taken:  0:00:18.813267d= 6 .........\n",
      "Time taken:  0:00:18.601622d= 6 .........\n",
      "Time taken:  0:00:18.781556d= 6 .........\n",
      "Time taken:  0:00:20.778194d= 6 .........\n",
      "Time taken:  0:00:24.787063d= 6 .........\n",
      "Time taken:  0:00:14.081838d= 6 .........\n",
      "Time taken:  0:00:13.808643d= 6 .........\n",
      "Time taken:  0:00:13.473188 d= 6 .........\n",
      "Time taken:  0:00:13.414871 d= 6 .........\n",
      "Time taken:  0:00:13.464786 d= 6 .........\n",
      "Time taken:  0:00:18.535697 d= 6 .........\n",
      "Time taken:  0:00:19.390983 d= 6 .........\n",
      "Time taken:  0:00:18.792488 d= 6 .........\n",
      "Time taken:  0:00:18.740008 d= 6 .........\n",
      "Time taken:  0:00:19.132173 d= 6 .........\n",
      "Time taken:  0:00:19.739030 d= 6 .........\n",
      "Time taken:  0:00:20.764033 d= 6 .........\n",
      "Time taken:  0:00:19.570299d= 7 .........\n",
      "Time taken:  0:00:19.127457d= 7 .........\n",
      "Time taken:  0:00:18.629799d= 7 .........\n",
      "Time taken:  0:00:18.744776d= 7 .........\n",
      "Time taken:  0:00:20.012243d= 7 .........\n",
      "Time taken:  0:00:19.979510d= 7 .........\n",
      "Time taken:  0:00:19.151297d= 7 .........\n",
      "Time taken:  0:00:14.955746d= 7 .........\n",
      "Time taken:  0:00:13.084301d= 7 .........\n",
      "Time taken:  0:00:12.844531d= 7 .........\n",
      "Time taken:  0:00:12.917193 d= 7 .........\n",
      "Time taken:  0:00:12.997565 d= 7 .........\n",
      "Time taken:  0:00:12.909659 d= 7 .........\n",
      "Time taken:  0:00:12.962703 d= 7 .........\n",
      "Time taken:  0:00:13.174608 d= 7 .........\n",
      "Time taken:  0:00:12.841703 d= 7 .........\n",
      "Time taken:  0:00:13.053987 d= 7 .........\n",
      "Time taken:  0:00:12.966596 d= 7 .........\n",
      "Time taken:  0:00:12.693930 d= 7 .........\n",
      "Time taken:  0:00:13.215989 d= 7 .........\n"
     ]
    }
   ],
   "source": [
    "d_arr = np.arange(1,8)\n",
    "runs = 20\n",
    "training_set_errors = np.zeros((len(d_arr),runs))\n",
    "test_set_errors = np.zeros((len(d_arr),runs))\n",
    "\n",
    "for d in d_arr:\n",
    "    for i in range(runs):\n",
    "        startTime = datetime.now()\n",
    "        X_train, X_test, y_train, y_test = allocate_training_test_sets(data, r=1/5)\n",
    "        W, alphas,train_errors = perceptron_train_ovo(X_train,y_train, d)\n",
    "        predictions, test_error = perceptron_test_ovo(X_test,X_train, y_test,W, alphas,d)\n",
    "        \n",
    "        training_set_errors[d-1, i] = train_errors[-1]\n",
    "        test_set_errors[d-1, i] = test_error\n",
    "        print(\"Now doing run \", i, \"/\", runs, \" for d=\", d,\".........\", end='\\r')\n",
    "        print(\"Time taken: \", datetime.now() - startTime )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training set error rate</th>\n",
       "      <th>Test set error rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2092 +- 0.0029</td>\n",
       "      <td>0.1720 +- 0.0366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1385 +- 0.0022</td>\n",
       "      <td>0.0955 +- 0.0152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1181 +- 0.0029</td>\n",
       "      <td>0.0707 +- 0.0054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.1105 +- 0.0026</td>\n",
       "      <td>0.0661 +- 0.0115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.1056 +- 0.0024</td>\n",
       "      <td>0.0641 +- 0.0087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.1051 +- 0.0016</td>\n",
       "      <td>0.0600 +- 0.0054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.1045 +- 0.0021</td>\n",
       "      <td>0.0626 +- 0.0088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Training set error rate Test set error rate\n",
       "1        0.2092 +- 0.0029    0.1720 +- 0.0366\n",
       "2        0.1385 +- 0.0022    0.0955 +- 0.0152\n",
       "3        0.1181 +- 0.0029    0.0707 +- 0.0054\n",
       "4        0.1105 +- 0.0026    0.0661 +- 0.0115\n",
       "5        0.1056 +- 0.0024    0.0641 +- 0.0087\n",
       "6        0.1051 +- 0.0016    0.0600 +- 0.0054\n",
       "7        0.1045 +- 0.0021    0.0626 +- 0.0088"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means_std = []\n",
    "for d in d_arr:\n",
    "    data_t = []\n",
    "    data_t.append(\"{0:.4f} +- {1:.4f}\".format(training_set_errors[d-1].mean() / len(y_train), \\\n",
    "                                            np.std(training_set_errors[d-1]) / len(y_train)))\n",
    "    data_t.append(\"{0:.4f} +- {1:.4f}\".format(test_set_errors[d-1].mean() / len(y_test), \\\n",
    "                                            np.std(test_set_errors[d-1]) / len(y_test)))\n",
    "    means_std.append(data_t)\n",
    "    \n",
    "df = pd.DataFrame(data=means_std, index=d_arr, columns=['Training set error rate', 'Test set error rate'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation - Polynomial Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This might need to be cleared up\n",
    "class Confusion:\n",
    "    def __init__(self, x, y, pred):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.pred = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "runs = 10\n",
    "\n",
    "d_stars = np.zeros(runs)\n",
    "test_errors = np.zeros(runs)\n",
    "confusion = np.zeros((10, 10))\n",
    "\n",
    "confusion_examples = dict()\n",
    "for i in range(10):\n",
    "    confusion_examples[i] = []\n",
    "\n",
    "mistakes_per_run = np.zeros(x.shape[0])\n",
    "    \n",
    "for j in range(runs):\n",
    "    print(\"WARNING: Change the number of runs to 20!!!\")\n",
    "    # In each run we will iterate through the d array and use all possible values of d\n",
    "    \n",
    "    # Allocate 80/20 percent for training and test set\n",
    "    X_train, X_test, y_train, y_test = allocate_training_test_sets(data, r=1/5)\n",
    "\n",
    "    error_CV_means = np.zeros(len(d_arr))\n",
    "    for i in range(len(d_arr)):\n",
    "        print(\"Now doing run \", j, \"/\", runs, \" for d=\", d_arr[i], \".........\", end='\\r')\n",
    "        error_CV_mean, _ = cross_validation(X_train, y_train, d_arr[i], k=5)\n",
    "        error_CV_means[i] = error_CV_mean\n",
    "\n",
    "    # Train in whole 80% now with d_star\n",
    "    d_stars[j] = CV_means.argmin()\n",
    "    \n",
    "    W, alphas,train_errors = perceptron_train_ovo(X_train,y_train, d_stars[j])\n",
    "    predictions, test_error = perceptron_test_ovo(X_test,X_train, y_test,W, alphas, d_stars[j])\n",
    "        \n",
    "    for i in range(len(y_train)):\n",
    "        pred_label = preds_train[i].argmax()\n",
    "        if pred_label != y_train[i]:\n",
    "            confusion[int(y_train[i]), pred_label] += 1\n",
    "            confusion_examples[int(y_train[i])].append(Confusion(X_train[i], y_train[i], pred_label))\n",
    "    # END WRONG\n",
    "    \n",
    "    test_errors[j] =  test_error/ len(y_test)\n",
    "    \n",
    "    # Test in all the data set, so that we know which ones\n",
    "    # are the \"toughest\" to predict in the whole data set. We can't really just do it on \n",
    "    # either the training or test set, as it is randomly split so order will not be pertained.\n",
    "    _, preds_all, confidences = perceptron_test(x, X_train, y, W, alphas, d_stars[j])\n",
    "    for i in range(x.shape[0]):\n",
    "        pred_label = preds_all[i].argmax()\n",
    "        if pred_label != y[i]:\n",
    "            mistakes_per_run[i] += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
