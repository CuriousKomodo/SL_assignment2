{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I: Supervised Learining "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import scipy\n",
    "import scipy.io as spio\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "import urllib\n",
    "from urllib.request import urlopen\n",
    "%matplotlib inline\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract data as an array from the url\n",
    "# link = \"http://www0.cs.ucl.ac.uk/staff/M.Herbster/SL/misc/zipcombo.dat\"\n",
    "filename = 'zipcombo.dat'\n",
    "training_filename = 'dtrain123.dat'\n",
    "test_filename = 'dtest123.dat'\n",
    "# urllib.request.urlretrieve(link, filename)\n",
    "data = np.loadtxt(filename)     # read numpy array from file\n",
    "# data = np.loadtxt(training_filename)     # read numpy array from file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiclass Perceptron with Polynomial Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[:,0]\n",
    "x = data[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Not sure if I should include bias before computing the Kernel? \n",
    "def add_bias(x):\n",
    "    x_with_bias = np.ones((x.shape[0],x.shape[1]+1))\n",
    "    x_with_bias[:,:-1] = x\n",
    "    return x_with_bias\n",
    "\n",
    "#Discuss the use of the this kernel. i.e. talk about non-linear seperability. \n",
    "def Polynomial_Kernel(x1,x2,d):\n",
    "    K = (x1 @ x2.T)**d\n",
    "    return K\n",
    "\n",
    "def transform_y(y):\n",
    "    #classes_num = len(y.unique())\n",
    "    #assuming that training set has all the numbers between min(y) and max(y)\n",
    "    classes_num = 10\n",
    "    m = len(y)\n",
    "    y_matrix = np.ones((m,classes_num))*(-1)\n",
    "    for i in range(m):\n",
    "        y_matrix[i,int(y[i])] = 1\n",
    "    return y_matrix\n",
    "\n",
    "def pairwise_distance_single(X): # distances of X training data, single X matrix\n",
    "    m =X.shape[0]\n",
    "    n = X.shape[1]\n",
    "    G = np.matmul(X,X.T)\n",
    "    DG = np.diag(G).reshape(G.shape[0],1)\n",
    "    distances_sq = np.matmul(DG,np.ones((G.shape[0],1)).T)+ np.matmul(np.ones((G.shape[1],1)),DG.T)-2.0*G\n",
    "    return distances_sq\n",
    "\n",
    "def pairwise_distance_double(X1,X2): # distances of X training data, double matrices, X1 and X2\n",
    "    X1_pow = (X1**2).sum(axis=1).reshape(X1.shape[0],1) #sum the rows, size m1 array\n",
    "    X2_pow = (X2**2).sum(axis=1).reshape(X2.shape[0],1) #sum the rows, size m2 array\n",
    "    G = np.matmul(X1,X2.T)\n",
    "    m1,m2 =G.shape[0],G.shape[1] \n",
    "    distances_sq = np.matmul(X1_pow,np.ones((m2,1)).T)+ np.matmul(np.ones((m1,1)),X2_pow.T)-2.0*G\n",
    "    return distances_sq\n",
    "\n",
    "def Gaussian_Kernel(distances_sq,c=1):\n",
    "    K = np.exp(-c*distances_sq)\n",
    "    return K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_kernel_single(x, d, kernel_choice):\n",
    "    if kernel_choice=='Polynomial':\n",
    "        K_train = Polynomial_Kernel(x,x,d)\n",
    "#         print(\"Constructed a Polynomial kernel for training\")\n",
    "    elif kernel_choice=='Gaussian':\n",
    "        pairwise_distances = pairwise_distance_single(x)\n",
    "        K_train = Gaussian_Kernel(pairwise_distances,c=d)\n",
    "#         print(\"Constructed a Gaussian kernel for training\")\n",
    "    else:\n",
    "        raise Exception(\"Unsupported value for kernel. Supported values: Polynomial, Gaussian\")\n",
    "    return K_train\n",
    "\n",
    "def calculate_kernel_double(x1, x2, d, kernel_choice):\n",
    "    if kernel_choice=='Polynomial':\n",
    "        K_train = Polynomial_Kernel(x1,x2,d)\n",
    "#         print(\"Constructed a Polynomial kernel for testing\")\n",
    "    elif kernel_choice=='Gaussian':\n",
    "        pairwise_distances = pairwise_distance_double(x1, x2)\n",
    "        K_train = Gaussian_Kernel(pairwise_distances,c=d)\n",
    "#         print(\"Constructed a Gaussian kernel for testing\")\n",
    "    else:\n",
    "        raise Exception(\"Unsupported value for kernel. Supported values: Polynomial, Gaussian\")\n",
    "    return K_train\n",
    "\n",
    "def perceptron_epoch(x, y, y_arr, alpha, K_train):\n",
    "    m = x.shape[0] #number of examples\n",
    "    errors = np.zeros(m)\n",
    "    num_errors = 0 #This should be bounded..? Maybe calculate the bound in the explanation\n",
    "\n",
    "    for t in range(m):\n",
    "        #find our training set\n",
    "        x_t = x[t,:] #of size (1,n)\n",
    "        y_t = y[t]\n",
    "        y_arr_t = y_arr[t,:] #of size (1,10) \n",
    "\n",
    "        #pred_t computes \\sum^{t-1}_{i=0} {(alpha_i K(x_t, x_i))}, which is regarded as the confidence in each class\n",
    "        pred_t = (alpha[:,:].T @K_train[t,:]).T\n",
    "        y_hat_t = np.where(pred_t==max(pred_t),1,0) #map the confidence to arrays of 1 and 0 for class\n",
    "\n",
    "        if pred_t.argmax()!=y_t:\n",
    "            #update the alpha, and weights, for all the classes that not the true class\n",
    "            num_errors +=1\n",
    "\n",
    "            #since we only want to update the weights related to first t-1 training data.\n",
    "            #note that alpha_t is np.zeros(10,1), \n",
    "            #and alpha_t is updated according to the real class, and the misclassified class.\n",
    "            #this version is not updated with alpha_prev\n",
    "\n",
    "            alpha_t = alpha[t,:] + np.where(y_arr_t> 0,1,0) + np.where(y_hat_t>0,-1,0) #(1,10)\n",
    "\n",
    "            #store alpha_t into the matrix for future reference\n",
    "            alpha[t,:] = alpha_t\n",
    "\n",
    "            #sandwich K(x_t, x_i) for i in [1,t-1] in a zeros array of size(m). \n",
    "            #reason being weight for one class is of size(m), but we only 'have enough data' to update the first t-1 terms.  \n",
    "            K_update = np.zeros((1,m))\n",
    "            K_update[:,:t] = K_train[t,:t] \n",
    "\n",
    "        errors[t] = num_errors\n",
    "    return alpha, errors\n",
    "\n",
    "#One vs. rest: train k classifiers to identify k classes\n",
    "def perceptron_train(x,y,d=2,kernel_choice='Polynomial', convergence_threshold=0.01):\n",
    "    m = x.shape[0] #number of examples\n",
    "    n = x.shape[1] #number of features\n",
    "    classes_num = 10 #number of classes \n",
    "     \n",
    "    error_per_epoch = []\n",
    "    y_arr = transform_y(y) \n",
    "    alpha = np.zeros((m,classes_num)) #Need to store alpha array at all iteration, as we need it to compute confidence\n",
    "    \n",
    "    K_train = calculate_kernel_single(x, d, kernel_choice)    \n",
    "    epochs = 0\n",
    "    while True:\n",
    "        alpha, errors = perceptron_epoch(x, y, y_arr, alpha, K_train)\n",
    "        \n",
    "        error_rate_current = error_per_epoch[-1] / x.shape[0] if epochs > 0 else 0\n",
    "        error_rate_next = errors[-1] / x.shape[0]\n",
    "\n",
    "        error_per_epoch.append(errors[-1])\n",
    "        if epochs > 0 and (error_rate_next > error_rate_current or \\\n",
    "            error_rate_current - error_rate_next < convergence_threshold):\n",
    "#             print(\"Stopping after \", epochs+1,\" epochs: error_next: \", error_rate_next,\", current: \", error_rate_current)\n",
    "            break\n",
    "            \n",
    "        epochs += 1\n",
    "\n",
    "    return alpha, error_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test this function, see if it is working properly\n",
    "alpha, error_per_epoch = perceptron_train(x,y,d=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "err is  0.021294902129490215\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[863.0, 378.0, 236.0, 198.0]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Plot number of misclassfication versus the number of training sets reviewed. \n",
    "ratio = np.asarray(error_per_epoch)/x.shape[0]\n",
    "err = error_per_epoch[-1]/x.shape[0]\n",
    "print(\"err is \", err)\n",
    "error_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Proportion of misclassified data points out of data points reviewed')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(ratio)\n",
    "plt.ylabel('Proportion of misclassfication')\n",
    "plt.xlabel('Number of data points reviewed')\n",
    "plt.title('Proportion of misclassified data points out of data points reviewed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1 - Basic Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "def allocate_training_test_sets(data,r =1/5):\n",
    "    X= data[:,1:]\n",
    "    y= data[:,0]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=r)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron_test(x_test,x_train,y_test, alphas, d, kernel_choice='Polynomial'):\n",
    "    K_test = calculate_kernel_double(x_train, x_test, d, kernel_choice)\n",
    "    \n",
    "    confidence = (alphas.T @ K_test).T\n",
    "    preds = np.zeros(confidence.shape)\n",
    "    mistakes = 0\n",
    "    for i in range(len(y_test)):\n",
    "        y_hat = confidence[i].argmax()\n",
    "        preds[i,y_hat] = 1\n",
    "        if y_hat != y_test[i]:\n",
    "            mistakes += 1\n",
    "    return mistakes, preds, confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mistakes:  68 , sample size:  1860\n",
      "Ratio mistakes/size:  0.03655913978494624\n"
     ]
    }
   ],
   "source": [
    "# CLEANUP in the end, This is just for testing, CLEANUP\n",
    "X_train, X_test, y_train, y_test = allocate_training_test_sets(data,r =1/5)\n",
    "alphas, train_errors = perceptron_train(X_train,y_train, 3)\n",
    "mistakes,_,_ = perceptron_test(X_test, X_train, y_test, alphas, 3)\n",
    "    \n",
    "print(\"Number of mistakes: \", mistakes, \", sample size: \", len(y_test))\n",
    "print(\"Ratio mistakes/size: \", mistakes/len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now doing run  2 / 2  for d= 7 .........\r"
     ]
    }
   ],
   "source": [
    "def basic_results(d_arr, kernel_choice, runs):\n",
    "    training_set_errors = np.zeros((len(d_arr),runs))\n",
    "    test_set_errors = np.zeros((len(d_arr),runs))\n",
    "    for d in d_arr:\n",
    "        for i in range(runs):\n",
    "            print(\"Now doing run \", i+1, \"/\", runs, \" for d=\", d,\".........\", end='\\r')\n",
    "            X_train, X_test, y_train, y_test = allocate_training_test_sets(data, r=1/5)\n",
    "            alphas,_ = perceptron_train(X_train,y_train, d, kernel_choice=kernel_choice)\n",
    "\n",
    "            train_errors,_,_ = perceptron_test(X_train, X_train, y_train, alphas,d, kernel_choice=kernel_choice)\n",
    "            test_errors,_,_ = perceptron_test(X_test,X_train, y_test,alphas,d, kernel_choice=kernel_choice)\n",
    "\n",
    "            training_set_errors[d-1, i] = train_errors / len(y_train)\n",
    "            test_set_errors[d-1, i] = test_errors / len(y_test)\n",
    "    return training_set_errors, test_set_errors\n",
    "            \n",
    "d_arr = np.arange(1,8)\n",
    "runs = 2\n",
    "training_set_errors, test_set_errors = basic_results(d_arr, 'Polynomial', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training set error rate</th>\n",
       "      <th>Test set error rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0800 +- 0.0091</td>\n",
       "      <td>0.1048 +- 0.0065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0218 +- 0.0015</td>\n",
       "      <td>0.0538 +- 0.0022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0092 +- 0.0026</td>\n",
       "      <td>0.0387 +- 0.0011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0026 +- 0.0003</td>\n",
       "      <td>0.0309 +- 0.0008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0029 +- 0.0006</td>\n",
       "      <td>0.0328 +- 0.0032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0022 +- 0.0007</td>\n",
       "      <td>0.0309 +- 0.0035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0019 +- 0.0003</td>\n",
       "      <td>0.0341 +- 0.0019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Training set error rate Test set error rate\n",
       "1        0.0800 +- 0.0091    0.1048 +- 0.0065\n",
       "2        0.0218 +- 0.0015    0.0538 +- 0.0022\n",
       "3        0.0092 +- 0.0026    0.0387 +- 0.0011\n",
       "4        0.0026 +- 0.0003    0.0309 +- 0.0008\n",
       "5        0.0029 +- 0.0006    0.0328 +- 0.0032\n",
       "6        0.0022 +- 0.0007    0.0309 +- 0.0035\n",
       "7        0.0019 +- 0.0003    0.0341 +- 0.0019"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def construct_dataframe_error_rates(training_set_errors, test_set_errors):\n",
    "    means_std = []\n",
    "    for d in d_arr:\n",
    "        data_t = []\n",
    "        data_t.append(\"{0:.4f} +- {1:.4f}\".format(training_set_errors[d-1].mean(), \\\n",
    "                                                np.std(training_set_errors[d-1])))\n",
    "        data_t.append(\"{0:.4f} +- {1:.4f}\".format(test_set_errors[d-1].mean(), \\\n",
    "                                                np.std(test_set_errors[d-1])))\n",
    "        means_std.append(data_t)\n",
    "    return means_std\n",
    "    \n",
    "means_std = construct_dataframe_error_rates(training_set_errors, test_set_errors)\n",
    "df = pd.DataFrame(data=means_std, index=d_arr, columns=['Training set error rate', 'Test set error rate'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2 - Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having already allocated x_train, now perform cross validation on x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(X, y, kernel_choice, d, k):\n",
    "    kf = KFold(n_splits=k, shuffle=True)\n",
    "    MSE_cv_arr = np.zeros(k)\n",
    "    i = 0\n",
    "    for train_index, cv_index in kf.split(X):\n",
    "        # Spit the matrix using the indices gained by the CV method and construct X and Y arrays\n",
    "        X_train = X[train_index]\n",
    "        X_cv = X[cv_index]\n",
    "        y_train = y[train_index]\n",
    "        y_cv = y[cv_index]\n",
    "    \n",
    "        # We are only interested in the alphas and not the MSE on the training set\n",
    "        alphas, errors = perceptron_train(X_train, y_train, d, kernel_choice = kernel_choice)\n",
    "        mistakes,_,_ = perceptron_test(X_cv, X_train, y_cv, alphas, d, kernel_choice = kernel_choice)\n",
    "        MSE_cv_arr[i] = mistakes / len(y_cv)\n",
    "        i += 1\n",
    "        \n",
    "    return MSE_cv_arr.mean(), np.std(MSE_cv_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Change the number of runs to 20!!!\n",
      "WARNING: Change the number of runs to 20!!!\n",
      "Now doing run  2 / 2  for d= 7 .........\r"
     ]
    }
   ],
   "source": [
    "def cv_process(d_arr, runs, kernel_choice, calculate_confusions):\n",
    "    d_stars = np.zeros(runs)\n",
    "    test_errors = np.zeros(runs)\n",
    "    confusions = []\n",
    "    mistakes_per_run = np.zeros(x.shape[0])\n",
    "\n",
    "    for j in range(runs):\n",
    "        confusion = np.zeros((10, 10))\n",
    "\n",
    "        print(\"WARNING: Change the number of runs to 20!!!\")\n",
    "        # In each run we will iterate through the d array and use all possible values of d\n",
    "\n",
    "        # Allocate 80/20 percent for training and test set\n",
    "        X_train, X_test, y_train, y_test = allocate_training_test_sets(data, r=1/5)\n",
    "\n",
    "        CV_means = np.zeros(len(d_arr))\n",
    "        for i in range(len(d_arr)):\n",
    "            print(\"Now doing run \", j+1, \"/\", runs, \" for d=\", d_arr[i], \".........\", end='\\r')\n",
    "            MSE_CV_mean, _ = cross_validation(X_train, y_train, kernel_choice, d_arr[i], k=5)\n",
    "            CV_means[i] = MSE_CV_mean\n",
    "\n",
    "        # Train in whole 80% now with d_star\n",
    "        d_stars[j] = CV_means.argmin()\n",
    "        alphas, errors = perceptron_train(X_train, y_train, d_stars[j], kernel_choice = kernel_choice)\n",
    "\n",
    "        mistakes,_,_ = perceptron_test(X_test, X_train, y_test, alphas, d_stars[j], kernel_choice = kernel_choice)\n",
    "        test_errors[j] = mistakes / len(y_test)\n",
    "        \n",
    "        if calculate_confusions:\n",
    "            # Test in all the data set, so that we know which ones\n",
    "            # are the \"toughest\" to predict in the whole data set. We can't really just do it on \n",
    "            # either the training or test set, as it is randomly split so order will not be pertained.\n",
    "            _, preds_all, confidences = perceptron_test(x, X_train, y, alphas, d_stars[j], kernel_choice = kernel_choice)\n",
    "            for i in range(x.shape[0]):\n",
    "                pred_label = preds_all[i].argmax()\n",
    "                if pred_label != y[i]:\n",
    "                    confusion[int(y[i]), pred_label] += 1\n",
    "                    mistakes_per_run[i] += 1\n",
    "\n",
    "            confusions.append(confusion)\n",
    "    return d_stars, test_errors, confusions, mistakes_per_run\n",
    "    \n",
    "runs = 2\n",
    "d_stars, test_errors, confusions, mistakes_per_run = cv_process(d_arr, runs, 'Polynomial', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean d*:  5.0  with std:  0.0\n",
      "Mean test error:  0.03521505376344086  with std:  0.0029569892473118274\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean d*: \", d_stars.mean(), \" with std: \", np.std(d_stars))\n",
    "print(\"Mean test error: \", test_errors.mean(), \" with std: \", np.std(test_errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3 - Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00 +- 0.00</td>\n",
       "      <td>0.00 +- 0.00</td>\n",
       "      <td>0.50 +- 0.50</td>\n",
       "      <td>1.00 +- 0.00</td>\n",
       "      <td>1.50 +- 0.50</td>\n",
       "      <td>0.50 +- 0.50</td>\n",
       "      <td>0.00 +- 0.00</td>\n",
       "      <td>0.00 +- 0.00</td>\n",
       "      <td>0.00 +- 0.00</td>\n",
       "      <td>0.00 +- 0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00 +- 0.00</td>\n",
       "      <td>0.00 +- 0.00</td>\n",
       "      <td>0.00 +- 0.00</td>\n",
       "      <td>1.00 +- 1.00</td>\n",
       "      <td>1.50 +- 0.50</td>\n",
       "      <td>0.50 +- 0.50</td>\n",
       "      <td>0.00 +- 0.00</td>\n",
       "      <td>0.50 +- 0.50</td>\n",
       "      <td>1.50 +- 1.50</td>\n",
       "      <td>1.50 +- 1.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.50 +- 1.50</td>\n",
       "      <td>0.50 +- 0.50</td>\n",
       "      <td>0.00 +- 0.00</td>\n",
       "      <td>1.50 +- 0.50</td>\n",
       "      <td>1.00 +- 0.00</td>\n",
       "      <td>0.50 +- 0.50</td>\n",
       "      <td>0.00 +- 0.00</td>\n",
       "      <td>1.50 +- 0.50</td>\n",
       "      <td>1.00 +- 0.00</td>\n",
       "      <td>1.00 +- 1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.00 +- 1.00</td>\n",
       "      <td>0.00 +- 0.00</td>\n",
       "      <td>1.00 +- 1.00</td>\n",
       "      <td>0.00 +- 0.00</td>\n",
       "      <td>0.00 +- 0.00</td>\n",
       "      <td>2.00 +- 1.00</td>\n",
       "      <td>0.00 +- 0.00</td>\n",
       "      <td>1.00 +- 0.00</td>\n",
       "      <td>6.00 +- 4.00</td>\n",
       "      <td>2.00 +- 2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00 +- 0.00</td>\n",
       "      <td>3.50 +- 0.50</td>\n",
       "      <td>0.50 +- 0.50</td>\n",
       "      <td>0.50 +- 0.50</td>\n",
       "      <td>0.00 +- 0.00</td>\n",
       "      <td>0.00 +- 0.00</td>\n",
       "      <td>1.00 +- 0.00</td>\n",
       "      <td>0.50 +- 0.50</td>\n",
       "      <td>0.50 +- 0.50</td>\n",
       "      <td>1.50 +- 0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.00 +- 2.00</td>\n",
       "      <td>0.00 +- 0.00</td>\n",
       "      <td>0.00 +- 0.00</td>\n",
       "      <td>2.50 +- 0.50</td>\n",
       "      <td>1.00 +- 1.00</td>\n",
       "      <td>0.00 +- 0.00</td>\n",
       "      <td>6.50 +- 1.50</td>\n",
       "      <td>0.00 +- 0.00</td>\n",
       "      <td>2.50 +- 1.50</td>\n",
       "      <td>2.50 +- 2.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.00 +- 1.00</td>\n",
       "      <td>1.00 +- 1.00</td>\n",
       "      <td>0.50 +- 0.50</td>\n",
       "      <td>0.00 +- 0.00</td>\n",
       "      <td>1.50 +- 0.50</td>\n",
       "      <td>1.00 +- 1.00</td>\n",
       "      <td>0.00 +- 0.00</td>\n",
       "      <td>0.00 +- 0.00</td>\n",
       "      <td>0.50 +- 0.50</td>\n",
       "      <td>0.00 +- 0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.00 +- 0.00</td>\n",
       "      <td>0.00 +- 0.00</td>\n",
       "      <td>1.00 +- 1.00</td>\n",
       "      <td>0.00 +- 0.00</td>\n",
       "      <td>4.00 +- 3.00</td>\n",
       "      <td>0.50 +- 0.50</td>\n",
       "      <td>0.00 +- 0.00</td>\n",
       "      <td>0.00 +- 0.00</td>\n",
       "      <td>0.50 +- 0.50</td>\n",
       "      <td>10.50 +- 6.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.00 +- 0.00</td>\n",
       "      <td>0.50 +- 0.50</td>\n",
       "      <td>0.50 +- 0.50</td>\n",
       "      <td>2.00 +- 2.00</td>\n",
       "      <td>0.50 +- 0.50</td>\n",
       "      <td>2.00 +- 2.00</td>\n",
       "      <td>0.00 +- 0.00</td>\n",
       "      <td>0.50 +- 0.50</td>\n",
       "      <td>0.00 +- 0.00</td>\n",
       "      <td>0.50 +- 0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.00 +- 0.00</td>\n",
       "      <td>0.00 +- 0.00</td>\n",
       "      <td>0.00 +- 0.00</td>\n",
       "      <td>0.50 +- 0.50</td>\n",
       "      <td>2.50 +- 0.50</td>\n",
       "      <td>0.00 +- 0.00</td>\n",
       "      <td>0.00 +- 0.00</td>\n",
       "      <td>2.00 +- 0.00</td>\n",
       "      <td>0.50 +- 0.50</td>\n",
       "      <td>0.00 +- 0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0             1             2             3             4  \\\n",
       "0  0.00 +- 0.00  0.00 +- 0.00  0.50 +- 0.50  1.00 +- 0.00  1.50 +- 0.50   \n",
       "1  0.00 +- 0.00  0.00 +- 0.00  0.00 +- 0.00  1.00 +- 1.00  1.50 +- 0.50   \n",
       "2  2.50 +- 1.50  0.50 +- 0.50  0.00 +- 0.00  1.50 +- 0.50  1.00 +- 0.00   \n",
       "3  1.00 +- 1.00  0.00 +- 0.00  1.00 +- 1.00  0.00 +- 0.00  0.00 +- 0.00   \n",
       "4  0.00 +- 0.00  3.50 +- 0.50  0.50 +- 0.50  0.50 +- 0.50  0.00 +- 0.00   \n",
       "5  2.00 +- 2.00  0.00 +- 0.00  0.00 +- 0.00  2.50 +- 0.50  1.00 +- 1.00   \n",
       "6  3.00 +- 1.00  1.00 +- 1.00  0.50 +- 0.50  0.00 +- 0.00  1.50 +- 0.50   \n",
       "7  0.00 +- 0.00  0.00 +- 0.00  1.00 +- 1.00  0.00 +- 0.00  4.00 +- 3.00   \n",
       "8  0.00 +- 0.00  0.50 +- 0.50  0.50 +- 0.50  2.00 +- 2.00  0.50 +- 0.50   \n",
       "9  0.00 +- 0.00  0.00 +- 0.00  0.00 +- 0.00  0.50 +- 0.50  2.50 +- 0.50   \n",
       "\n",
       "              5             6             7             8              9  \n",
       "0  0.50 +- 0.50  0.00 +- 0.00  0.00 +- 0.00  0.00 +- 0.00   0.00 +- 0.00  \n",
       "1  0.50 +- 0.50  0.00 +- 0.00  0.50 +- 0.50  1.50 +- 1.50   1.50 +- 1.50  \n",
       "2  0.50 +- 0.50  0.00 +- 0.00  1.50 +- 0.50  1.00 +- 0.00   1.00 +- 1.00  \n",
       "3  2.00 +- 1.00  0.00 +- 0.00  1.00 +- 0.00  6.00 +- 4.00   2.00 +- 2.00  \n",
       "4  0.00 +- 0.00  1.00 +- 0.00  0.50 +- 0.50  0.50 +- 0.50   1.50 +- 0.50  \n",
       "5  0.00 +- 0.00  6.50 +- 1.50  0.00 +- 0.00  2.50 +- 1.50   2.50 +- 2.50  \n",
       "6  1.00 +- 1.00  0.00 +- 0.00  0.00 +- 0.00  0.50 +- 0.50   0.00 +- 0.00  \n",
       "7  0.50 +- 0.50  0.00 +- 0.00  0.00 +- 0.00  0.50 +- 0.50  10.50 +- 6.50  \n",
       "8  2.00 +- 2.00  0.00 +- 0.00  0.50 +- 0.50  0.00 +- 0.00   0.50 +- 0.50  \n",
       "9  0.00 +- 0.00  0.00 +- 0.00  2.00 +- 0.00  0.50 +- 0.50   0.00 +- 0.00  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Might need to use pandas for it\n",
    "confusions_matrix = []\n",
    "for i in range(10):\n",
    "    confusions_i = []\n",
    "    for j in range(10):\n",
    "        confusions_ij = np.asarray([confusions[r][i,j] for r in range(runs)])\n",
    "        confusions_i.append(\"{0:.2f} +- {1:.2f}\".format(confusions_ij.mean(), np.std(confusions_ij)))\n",
    "    confusions_matrix.append(confusions_i)\n",
    "    \n",
    "df = pd.DataFrame(data=confusions_matrix)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4 - Hardest numbers to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x2160 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We only have to show 5, but let's show 10 for the purposes of seeingthat indeed the first 5 are the worst\n",
    "indices = np.flip(np.argsort(mistakes_per_run))[:10]\n",
    "\n",
    "plt.figure(figsize=(30,30))\n",
    "\n",
    "k = 1\n",
    "for i in indices:\n",
    "    a1 = plt.subplot(1, 10, k)\n",
    "    pixels = np.array(x[i], dtype='uint8')\n",
    "    pixels = pixels.reshape((16, 16))\n",
    "    plt.title(\"Real: {0}\".format(y[i]))\n",
    "    a1.imshow(pixels, cmap='gray')\n",
    "    k+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q5 - Gaussian Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now doing run  2 / 2  for d= 7 .........\r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training set error rate</th>\n",
       "      <th>Test set error rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0000 +- 0.0000</td>\n",
       "      <td>0.0565 +- 0.0081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0001 +- 0.0001</td>\n",
       "      <td>0.0616 +- 0.0024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0000 +- 0.0000</td>\n",
       "      <td>0.0629 +- 0.0043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0000 +- 0.0000</td>\n",
       "      <td>0.0621 +- 0.0024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0001 +- 0.0001</td>\n",
       "      <td>0.0704 +- 0.0059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0000 +- 0.0000</td>\n",
       "      <td>0.0804 +- 0.0013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0000 +- 0.0000</td>\n",
       "      <td>0.0968 +- 0.0075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Training set error rate Test set error rate\n",
       "1        0.0000 +- 0.0000    0.0565 +- 0.0081\n",
       "2        0.0001 +- 0.0001    0.0616 +- 0.0024\n",
       "3        0.0000 +- 0.0000    0.0629 +- 0.0043\n",
       "4        0.0000 +- 0.0000    0.0621 +- 0.0024\n",
       "5        0.0001 +- 0.0001    0.0704 +- 0.0059\n",
       "6        0.0000 +- 0.0000    0.0804 +- 0.0013\n",
       "7        0.0000 +- 0.0000    0.0968 +- 0.0075"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runs = 2\n",
    "d_arr = np.arange(1,8)\n",
    "\n",
    "training_set_errors, test_set_errors = basic_results(d_arr, 'Gaussian', runs)\n",
    "means_std = construct_dataframe_error_rates(training_set_errors, test_set_errors)\n",
    "df = pd.DataFrame(data=means_std, index=d_arr, columns=['Training set error rate', 'Test set error rate'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Change the number of runs to 20!!!\n",
      "WARNING: Change the number of runs to 20!!!\n",
      "Mean d*:  1.0  with std:  1.07 .........\n",
      "Mean test error:  0.48655913978494625  with std:  0.4295698924731183\n"
     ]
    }
   ],
   "source": [
    "#Cross Validation with Gaussian Kernel, find c_star\n",
    "runs = 2\n",
    "d_stars, test_errors, confusions, mistakes_per_run = cv_process(d_arr, runs, 'Gaussian', False)\n",
    "print(\"Mean d*: \", d_stars.mean(), \" with std: \", np.std(d_stars))\n",
    "print(\"Mean test error: \", test_errors.mean(), \" with std: \", np.std(test_errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q6 - Choose an alternative method to generalise k-classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q7 - Choose two more algorithms to compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One against rest approach\n",
    "#Problem: What is the hyperparameter to be tuned? C-value: C = 1/lambda, which is the regularization coefficient. \n",
    "#https://stackoverflow.com/questions/21816346/fine-tuning-parameters-in-logistic-regression\n",
    "#http://dataaspirant.com/2017/05/15/implement-multinomial-logistic-regression-python/\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X_train, X_test, y_train, y_test = allocate_training_test_sets(data,r =1/5)\n",
    "# Train multi-classification model with logistic regression\n",
    "lr = LogisticRegression(C=1,random_state=0, solver='newton-cg',multi_class='multinomial').fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Logistic regression Train Accuracy ::  0.9904544232320516\n",
      "Multinomial Logistic regression Test Accuracy ::  0.9354838709677419\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "#print (\"Logistic regression Train Accuracy :: \", metrics.accuracy_score(y_train, lr.predict(x_train)))\n",
    "#print (\"Logistic regression Test Accuracy :: \", metrics.accuracy_score(y_test, lr.predict(x_test)))\n",
    "print (\"Multinomial Logistic regression Train Accuracy :: \", metrics.accuracy_score(y_train, lr.predict(X_train)))\n",
    "print (\"Multinomial Logistic regression Test Accuracy :: \", metrics.accuracy_score(y_test, lr.predict(X_test)))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Different ideas - LR uses probability theory, it'd be interest to compare with perceptron which is simply geometric. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#One against one approach, or One against All approach? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Maybe logistic regression and SVM. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
