{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I: Supervised Learining "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import scipy\n",
    "import scipy.io as spio\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "import urllib\n",
    "from urllib.request import urlopen\n",
    "%matplotlib inline\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract data as an array from the url\n",
    "# link = \"http://www0.cs.ucl.ac.uk/staff/M.Herbster/SL/misc/zipcombo.dat\"\n",
    "filename = 'zipcombo.dat'\n",
    "training_filename = 'dtrain123.dat'\n",
    "test_filename = 'dtest123.dat'\n",
    "# urllib.request.urlretrieve(link, filename)\n",
    "data = np.loadtxt(filename)     # read numpy array from file\n",
    "# data = np.loadtxt(training_filename)     # read numpy array from file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiclass Perceptron with Polynomial Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[:,0]\n",
    "x = data[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Not sure if I should include bias before computing the Kernel? \n",
    "def add_bias(x):\n",
    "    x_with_bias = np.ones((x.shape[0],x.shape[1]+1))\n",
    "    x_with_bias[:,:-1] = x\n",
    "    return x_with_bias\n",
    "\n",
    "#Discuss the use of the this kernel. i.e. talk about non-linear seperability. \n",
    "def Polynomial_Kernel(x1,x2,d):\n",
    "    K = (x1 @ x2.T)**d\n",
    "    return K\n",
    "\n",
    "def transform_y(y):\n",
    "    #classes_num = len(y.unique())\n",
    "    #assuming that training set has all the numbers between min(y) and max(y)\n",
    "    classes_num = 10\n",
    "    m = len(y)\n",
    "    y_matrix = np.ones((m,classes_num))*(-1)\n",
    "    for i in range(m):\n",
    "        y_matrix[i,int(y[i])] = 1\n",
    "    return y_matrix\n",
    "\n",
    "def pairwise_distance_single(X): # distances of X training data, single X matrix\n",
    "    m =X.shape[0]\n",
    "    n = X.shape[1]\n",
    "    G = np.matmul(X,X.T)\n",
    "    DG = np.diag(G).reshape(G.shape[0],1)\n",
    "    distances_sq = np.matmul(DG,np.ones((G.shape[0],1)).T)+ np.matmul(np.ones((G.shape[1],1)),DG.T)-2.0*G\n",
    "    return distances_sq\n",
    "\n",
    "def pairwise_distance_double(X1,X2): # distances of X training data, double matrices, X1 and X2\n",
    "    X1_pow = (X1**2).sum(axis=1).reshape(X1.shape[0],1) #sum the rows, size m1 array\n",
    "    X2_pow = (X2**2).sum(axis=1).reshape(X2.shape[0],1) #sum the rows, size m2 array\n",
    "    G = np.matmul(X1,X2.T)\n",
    "    m1,m2 =G.shape[0],G.shape[1] \n",
    "    distances_sq = np.matmul(X1_pow,np.ones((m2,1)).T)+ np.matmul(np.ones((m1,1)),X2_pow.T)-2.0*G\n",
    "    return distances_sq\n",
    "\n",
    "def Gaussian_Kernel(distances_sq,c=1):\n",
    "    K = np.exp(-c*distances_sq)\n",
    "    return K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_kernel_single(x, d, kernel_choice):\n",
    "    if kernel_choice=='Polynomial':\n",
    "        K_train = Polynomial_Kernel(x,x,d)\n",
    "#         print(\"Constructed a Polynomial kernel for training\")\n",
    "    elif kernel_choice=='Gaussian':\n",
    "        pairwise_distances = pairwise_distance_single(x)\n",
    "        K_train = Gaussian_Kernel(pairwise_distances,c=d)\n",
    "#         print(\"Constructed a Gaussian kernel for training\")\n",
    "    else:\n",
    "        raise Exception(\"Unsupported value for kernel. Supported values: Polynomial, Gaussian\")\n",
    "    return K_train\n",
    "\n",
    "def calculate_kernel_double(x1, x2, d, kernel_choice):\n",
    "    if kernel_choice=='Polynomial':\n",
    "        K_train = Polynomial_Kernel(x1,x2,d)\n",
    "#         print(\"Constructed a Polynomial kernel for testing\")\n",
    "    elif kernel_choice=='Gaussian':\n",
    "        pairwise_distances = pairwise_distance_double(x1, x2)\n",
    "        K_train = Gaussian_Kernel(pairwise_distances,c=d)\n",
    "#         print(\"Constructed a Gaussian kernel for testing\")\n",
    "    else:\n",
    "        raise Exception(\"Unsupported value for kernel. Supported values: Polynomial, Gaussian\")\n",
    "    return K_train\n",
    "\n",
    "def perceptron_epoch(x, y, y_arr, alpha, K_train):\n",
    "    m = x.shape[0] #number of examples\n",
    "    errors = np.zeros(m)\n",
    "    num_errors = 0 #This should be bounded..? Maybe calculate the bound in the explanation\n",
    "\n",
    "    for t in range(m):\n",
    "        #find our training set\n",
    "        x_t = x[t,:] #of size (1,n)\n",
    "        y_t = y[t]\n",
    "        y_arr_t = y_arr[t,:] #of size (1,10) \n",
    "\n",
    "        #pred_t computes \\sum^{t-1}_{i=0} {(alpha_i K(x_t, x_i))}, which is regarded as the confidence in each class\n",
    "        pred_t = (alpha[:,:].T @K_train[t,:]).T\n",
    "        y_hat_t = np.where(pred_t==max(pred_t),1,0) #map the confidence to arrays of 1 and 0 for class\n",
    "\n",
    "        if pred_t.argmax()!=y_t:\n",
    "            #update the alpha, and weights, for all the classes that not the true class\n",
    "            num_errors +=1\n",
    "\n",
    "            #since we only want to update the weights related to first t-1 training data.\n",
    "            #note that alpha_t is np.zeros(10,1), \n",
    "            #and alpha_t is updated according to the real class, and the misclassified class.\n",
    "            #this version is not updated with alpha_prev\n",
    "\n",
    "            alpha_t = alpha[t,:] + np.where(y_arr_t> 0,1,0) + np.where(y_hat_t>0,-1,0) #(1,10)\n",
    "\n",
    "            #store alpha_t into the matrix for future reference\n",
    "            alpha[t,:] = alpha_t\n",
    "\n",
    "            #sandwich K(x_t, x_i) for i in [1,t-1] in a zeros array of size(m). \n",
    "            #reason being weight for one class is of size(m), but we only 'have enough data' to update the first t-1 terms.  \n",
    "            K_update = np.zeros((1,m))\n",
    "            K_update[:,:t] = K_train[t,:t] \n",
    "\n",
    "        errors[t] = num_errors\n",
    "    return alpha, errors\n",
    "\n",
    "#One vs. rest: train k classifiers to identify k classes\n",
    "def perceptron_train(x,y,d=2,kernel_choice='Polynomial', convergence_threshold=0.01):\n",
    "    m = x.shape[0] #number of examples\n",
    "    n = x.shape[1] #number of features\n",
    "    classes_num = 10 #number of classes \n",
    "     \n",
    "    error_per_epoch = []\n",
    "    y_arr = transform_y(y) \n",
    "    alpha = np.zeros((m,classes_num)) #Need to store alpha array at all iteration, as we need it to compute confidence\n",
    "    \n",
    "    K_train = calculate_kernel_single(x, d, kernel_choice)    \n",
    "    epochs = 0\n",
    "    while True:\n",
    "        alpha, errors = perceptron_epoch(x, y, y_arr, alpha, K_train)\n",
    "        \n",
    "        error_rate_current = error_per_epoch[-1] / x.shape[0] if epochs > 0 else 0\n",
    "        error_rate_next = errors[-1] / x.shape[0]\n",
    "\n",
    "        error_per_epoch.append(errors[-1])\n",
    "        if epochs > 0 and (error_rate_next > error_rate_current or \\\n",
    "            error_rate_current - error_rate_next < convergence_threshold):\n",
    "#             print(\"Stopping after \", epochs+1,\" epochs: error_next: \", error_rate_next,\", current: \", error_rate_current)\n",
    "            break\n",
    "            \n",
    "        epochs += 1\n",
    "\n",
    "    return alpha, error_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test this function, see if it is working properly\n",
    "alpha, error_per_epoch = perceptron_train(x,y,d=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "err is  0.021294902129490215\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[863.0, 378.0, 236.0, 198.0]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Plot number of misclassfication versus the number of training sets reviewed. \n",
    "ratio = np.asarray(error_per_epoch)/x.shape[0]\n",
    "err = error_per_epoch[-1]/x.shape[0]\n",
    "print(\"err is \", err)\n",
    "error_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Proportion of misclassified data points out of data points reviewed')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(ratio)\n",
    "plt.ylabel('Proportion of misclassfication')\n",
    "plt.xlabel('Number of data points reviewed')\n",
    "plt.title('Proportion of misclassified data points out of data points reviewed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1 - Basic Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "def allocate_training_test_sets(data,r =1/5):\n",
    "    X= data[:,1:]\n",
    "    y= data[:,0]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=r)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron_test(x_test,x_train,y_test, alphas, d, kernel_choice='Polynomial'):\n",
    "    K_test = calculate_kernel_double(x_train, x_test, d, kernel_choice)\n",
    "    \n",
    "    confidence = (alphas.T @ K_test).T\n",
    "    preds = np.zeros(confidence.shape)\n",
    "    mistakes = 0\n",
    "    for i in range(len(y_test)):\n",
    "        y_hat = confidence[i].argmax()\n",
    "        preds[i,y_hat] = 1\n",
    "        if y_hat != y_test[i]:\n",
    "            mistakes += 1\n",
    "    return mistakes, preds, confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mistakes:  100 , sample size:  1860\n",
      "Ratio mistakes/size:  0.053763440860215055\n"
     ]
    }
   ],
   "source": [
    "# CLEANUP in the end, This is just for testing, CLEANUP\n",
    "X_train, X_test, y_train, y_test = allocate_training_test_sets(data,r =1/5)\n",
    "alphas, train_errors = perceptron_train(X_train,y_train, 3)\n",
    "mistakes,_,_ = perceptron_test(X_test, X_train, y_test, alphas, 3)\n",
    "    \n",
    "print(\"Number of mistakes: \", mistakes, \", sample size: \", len(y_test))\n",
    "print(\"Ratio mistakes/size: \", mistakes/len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now doing run  20 / 20  for d= 7 .........\r"
     ]
    }
   ],
   "source": [
    "def basic_results(d_arr, kernel_choice, runs):\n",
    "    training_set_errors = np.zeros((len(d_arr),runs))\n",
    "    test_set_errors = np.zeros((len(d_arr),runs))\n",
    "    for d in d_arr:\n",
    "        for i in range(runs):\n",
    "            print(\"Now doing run \", i+1, \"/\", runs, \" for d=\", d,\".........\", end='\\r')\n",
    "            X_train, X_test, y_train, y_test = allocate_training_test_sets(data, r=1/5)\n",
    "            alphas,_ = perceptron_train(X_train,y_train, d, kernel_choice=kernel_choice)\n",
    "\n",
    "            train_errors,_,_ = perceptron_test(X_train, X_train, y_train, alphas,d, kernel_choice=kernel_choice)\n",
    "            test_errors,_,_ = perceptron_test(X_test,X_train, y_test,alphas,d, kernel_choice=kernel_choice)\n",
    "\n",
    "            training_set_errors[d-1, i] = train_errors / len(y_train)\n",
    "            test_set_errors[d-1, i] = test_errors / len(y_test)\n",
    "    return training_set_errors, test_set_errors\n",
    "            \n",
    "d_arr = np.arange(1,8)\n",
    "runs = 20\n",
    "training_set_errors, test_set_errors = basic_results(d_arr, 'Polynomial', runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training set error rate</th>\n",
       "      <th>Test set error rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0810 +- 0.0167</td>\n",
       "      <td>0.0975 +- 0.0172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0156 +- 0.0071</td>\n",
       "      <td>0.0462 +- 0.0098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0076 +- 0.0042</td>\n",
       "      <td>0.0402 +- 0.0051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0044 +- 0.0023</td>\n",
       "      <td>0.0356 +- 0.0063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0031 +- 0.0015</td>\n",
       "      <td>0.0340 +- 0.0043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0022 +- 0.0010</td>\n",
       "      <td>0.0324 +- 0.0049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0024 +- 0.0021</td>\n",
       "      <td>0.0358 +- 0.0046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Training set error rate Test set error rate\n",
       "1        0.0810 +- 0.0167    0.0975 +- 0.0172\n",
       "2        0.0156 +- 0.0071    0.0462 +- 0.0098\n",
       "3        0.0076 +- 0.0042    0.0402 +- 0.0051\n",
       "4        0.0044 +- 0.0023    0.0356 +- 0.0063\n",
       "5        0.0031 +- 0.0015    0.0340 +- 0.0043\n",
       "6        0.0022 +- 0.0010    0.0324 +- 0.0049\n",
       "7        0.0024 +- 0.0021    0.0358 +- 0.0046"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def construct_dataframe_error_rates(training_set_errors, test_set_errors):\n",
    "    means_std = []\n",
    "    for d in d_arr:\n",
    "        data_t = []\n",
    "        data_t.append(\"{0:.4f} +- {1:.4f}\".format(training_set_errors[d-1].mean(), \\\n",
    "                                                np.std(training_set_errors[d-1])))\n",
    "        data_t.append(\"{0:.4f} +- {1:.4f}\".format(test_set_errors[d-1].mean(), \\\n",
    "                                                np.std(test_set_errors[d-1])))\n",
    "        means_std.append(data_t)\n",
    "    return means_std\n",
    "    \n",
    "means_std = construct_dataframe_error_rates(training_set_errors, test_set_errors)\n",
    "df = pd.DataFrame(data=means_std, index=d_arr, columns=['Training set error rate', 'Test set error rate'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2 - Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having already allocated x_train, now perform cross validation on x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(X, y, kernel_choice, d, k):\n",
    "    kf = KFold(n_splits=k, shuffle=True)\n",
    "    MSE_cv_arr = np.zeros(k)\n",
    "    i = 0\n",
    "    for train_index, cv_index in kf.split(X):\n",
    "        # Spit the matrix using the indices gained by the CV method and construct X and Y arrays\n",
    "        X_train = X[train_index]\n",
    "        X_cv = X[cv_index]\n",
    "        y_train = y[train_index]\n",
    "        y_cv = y[cv_index]\n",
    "    \n",
    "        # We are only interested in the alphas and not the MSE on the training set\n",
    "        alphas, errors = perceptron_train(X_train, y_train, d, kernel_choice = kernel_choice)\n",
    "        mistakes,_,_ = perceptron_test(X_cv, X_train, y_cv, alphas, d, kernel_choice = kernel_choice)\n",
    "        MSE_cv_arr[i] = mistakes / len(y_cv)\n",
    "        i += 1\n",
    "        \n",
    "    return MSE_cv_arr.mean(), np.std(MSE_cv_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Change the number of runs to 20!!!\n",
      "WARNING: Change the number of runs to 20!!!\n",
      "WARNING: Change the number of runs to 20!!!\n",
      "WARNING: Change the number of runs to 20!!!\n",
      "WARNING: Change the number of runs to 20!!!\n",
      "WARNING: Change the number of runs to 20!!!\n",
      "WARNING: Change the number of runs to 20!!!\n",
      "WARNING: Change the number of runs to 20!!!\n",
      "WARNING: Change the number of runs to 20!!!\n",
      "WARNING: Change the number of runs to 20!!!\n",
      "WARNING: Change the number of runs to 20!!!\n",
      "WARNING: Change the number of runs to 20!!!\n",
      "WARNING: Change the number of runs to 20!!!\n",
      "WARNING: Change the number of runs to 20!!!\n",
      "WARNING: Change the number of runs to 20!!!\n",
      "WARNING: Change the number of runs to 20!!!\n",
      "WARNING: Change the number of runs to 20!!!\n",
      "WARNING: Change the number of runs to 20!!!\n",
      "WARNING: Change the number of runs to 20!!!\n",
      "WARNING: Change the number of runs to 20!!!\n",
      "Now doing run  20 / 20  for d= 7 .........\r"
     ]
    }
   ],
   "source": [
    "def cv_process(d_arr, runs, kernel_choice, calculate_confusions):\n",
    "    d_stars = np.zeros(runs)\n",
    "    test_errors = np.zeros(runs)\n",
    "    confusions = []\n",
    "    mistakes_per_run = np.zeros(x.shape[0])\n",
    "\n",
    "    for j in range(runs):\n",
    "        confusion = np.zeros((10, 10))\n",
    "\n",
    "        print(\"WARNING: Change the number of runs to 20!!!\")\n",
    "        # In each run we will iterate through the d array and use all possible values of d\n",
    "\n",
    "        # Allocate 80/20 percent for training and test set\n",
    "        X_train, X_test, y_train, y_test = allocate_training_test_sets(data, r=1/5)\n",
    "\n",
    "        CV_means = np.zeros(len(d_arr))\n",
    "        for i in range(len(d_arr)):\n",
    "            print(\"Now doing run \", j+1, \"/\", runs, \" for d=\", d_arr[i], \".........\", end='\\r')\n",
    "            MSE_CV_mean, _ = cross_validation(X_train, y_train, kernel_choice, d_arr[i], k=5)\n",
    "            CV_means[i] = MSE_CV_mean\n",
    "\n",
    "        # Train in whole 80% now with d_star\n",
    "        d_stars[j] = CV_means.argmin()\n",
    "        alphas, errors = perceptron_train(X_train, y_train, d_stars[j], kernel_choice = kernel_choice)\n",
    "\n",
    "        mistakes,_,_ = perceptron_test(X_test, X_train, y_test, alphas, d_stars[j], kernel_choice = kernel_choice)\n",
    "        test_errors[j] = mistakes / len(y_test)\n",
    "        \n",
    "        if calculate_confusions:\n",
    "            # Test in all the data set, so that we know which ones\n",
    "            # are the \"toughest\" to predict in the whole data set. We can't really just do it on \n",
    "            # either the training or test set, as it is randomly split so order will not be pertained.\n",
    "            _, preds_all, confidences = perceptron_test(x, X_train, y, alphas, d_stars[j], kernel_choice = kernel_choice)\n",
    "            for i in range(x.shape[0]):\n",
    "                pred_label = preds_all[i].argmax()\n",
    "                if pred_label != y[i]:\n",
    "                    confusion[int(y[i]), pred_label] += 1\n",
    "                    mistakes_per_run[i] += 1\n",
    "\n",
    "            confusions.append(confusion)\n",
    "    return d_stars, test_errors, confusions, mistakes_per_run\n",
    "    \n",
    "runs = 20\n",
    "d_stars, test_errors, confusions, mistakes_per_run = cv_process(d_arr, runs, 'Polynomial', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean d*:  5.1  with std:  0.8306623862918076\n",
      "Mean test error:  0.034435483870967745  with std:  0.005160940288309699\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean d*: \", d_stars.mean(), \" with std: \", np.std(d_stars))\n",
    "print(\"Mean test error: \", test_errors.mean(), \" with std: \", np.std(test_errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3 - Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00 +- 0.00</td>\n",
       "      <td>0.10 +- 0.30</td>\n",
       "      <td>1.25 +- 1.13</td>\n",
       "      <td>0.65 +- 0.91</td>\n",
       "      <td>0.30 +- 0.46</td>\n",
       "      <td>1.05 +- 0.80</td>\n",
       "      <td>1.65 +- 1.74</td>\n",
       "      <td>0.10 +- 0.30</td>\n",
       "      <td>0.35 +- 0.57</td>\n",
       "      <td>0.25 +- 0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00 +- 0.00</td>\n",
       "      <td>0.00 +- 0.00</td>\n",
       "      <td>0.30 +- 0.46</td>\n",
       "      <td>0.20 +- 0.51</td>\n",
       "      <td>0.70 +- 1.10</td>\n",
       "      <td>0.05 +- 0.22</td>\n",
       "      <td>0.55 +- 0.80</td>\n",
       "      <td>0.50 +- 0.81</td>\n",
       "      <td>0.45 +- 0.67</td>\n",
       "      <td>0.50 +- 0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.20 +- 1.40</td>\n",
       "      <td>0.35 +- 0.57</td>\n",
       "      <td>0.00 +- 0.00</td>\n",
       "      <td>2.10 +- 1.26</td>\n",
       "      <td>2.20 +- 2.50</td>\n",
       "      <td>0.45 +- 0.86</td>\n",
       "      <td>0.25 +- 0.43</td>\n",
       "      <td>1.85 +- 1.35</td>\n",
       "      <td>0.90 +- 1.41</td>\n",
       "      <td>0.00 +- 0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.40 +- 0.73</td>\n",
       "      <td>0.00 +- 0.00</td>\n",
       "      <td>1.50 +- 1.32</td>\n",
       "      <td>0.00 +- 0.00</td>\n",
       "      <td>0.15 +- 0.36</td>\n",
       "      <td>5.00 +- 5.18</td>\n",
       "      <td>0.05 +- 0.22</td>\n",
       "      <td>0.80 +- 0.98</td>\n",
       "      <td>2.50 +- 2.46</td>\n",
       "      <td>0.35 +- 0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.20 +- 0.51</td>\n",
       "      <td>3.60 +- 1.28</td>\n",
       "      <td>1.60 +- 2.20</td>\n",
       "      <td>0.35 +- 0.57</td>\n",
       "      <td>0.00 +- 0.00</td>\n",
       "      <td>0.40 +- 0.73</td>\n",
       "      <td>1.60 +- 1.74</td>\n",
       "      <td>0.70 +- 0.84</td>\n",
       "      <td>0.20 +- 0.51</td>\n",
       "      <td>3.05 +- 2.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.55 +- 1.12</td>\n",
       "      <td>0.15 +- 0.36</td>\n",
       "      <td>0.70 +- 0.90</td>\n",
       "      <td>2.75 +- 2.70</td>\n",
       "      <td>0.75 +- 1.09</td>\n",
       "      <td>0.00 +- 0.00</td>\n",
       "      <td>2.00 +- 2.00</td>\n",
       "      <td>0.50 +- 0.50</td>\n",
       "      <td>1.30 +- 1.38</td>\n",
       "      <td>0.50 +- 0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.75 +- 1.58</td>\n",
       "      <td>0.75 +- 0.83</td>\n",
       "      <td>0.80 +- 1.08</td>\n",
       "      <td>0.00 +- 0.00</td>\n",
       "      <td>0.95 +- 1.02</td>\n",
       "      <td>0.90 +- 0.77</td>\n",
       "      <td>0.00 +- 0.00</td>\n",
       "      <td>0.00 +- 0.00</td>\n",
       "      <td>0.70 +- 0.78</td>\n",
       "      <td>0.05 +- 0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.05 +- 0.22</td>\n",
       "      <td>0.90 +- 1.79</td>\n",
       "      <td>0.65 +- 1.35</td>\n",
       "      <td>0.30 +- 0.56</td>\n",
       "      <td>1.15 +- 1.11</td>\n",
       "      <td>0.40 +- 1.11</td>\n",
       "      <td>0.00 +- 0.00</td>\n",
       "      <td>0.00 +- 0.00</td>\n",
       "      <td>1.05 +- 0.97</td>\n",
       "      <td>4.75 +- 9.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.00 +- 0.95</td>\n",
       "      <td>0.95 +- 1.47</td>\n",
       "      <td>1.80 +- 1.83</td>\n",
       "      <td>2.25 +- 2.32</td>\n",
       "      <td>1.05 +- 1.02</td>\n",
       "      <td>2.10 +- 1.89</td>\n",
       "      <td>0.90 +- 1.14</td>\n",
       "      <td>0.90 +- 1.87</td>\n",
       "      <td>0.00 +- 0.00</td>\n",
       "      <td>1.15 +- 1.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.30 +- 0.56</td>\n",
       "      <td>0.55 +- 1.24</td>\n",
       "      <td>0.35 +- 0.48</td>\n",
       "      <td>0.45 +- 0.74</td>\n",
       "      <td>3.60 +- 4.51</td>\n",
       "      <td>0.50 +- 0.74</td>\n",
       "      <td>0.00 +- 0.00</td>\n",
       "      <td>3.85 +- 4.45</td>\n",
       "      <td>0.40 +- 0.80</td>\n",
       "      <td>0.00 +- 0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0             1             2             3             4  \\\n",
       "0  0.00 +- 0.00  0.10 +- 0.30  1.25 +- 1.13  0.65 +- 0.91  0.30 +- 0.46   \n",
       "1  0.00 +- 0.00  0.00 +- 0.00  0.30 +- 0.46  0.20 +- 0.51  0.70 +- 1.10   \n",
       "2  1.20 +- 1.40  0.35 +- 0.57  0.00 +- 0.00  2.10 +- 1.26  2.20 +- 2.50   \n",
       "3  0.40 +- 0.73  0.00 +- 0.00  1.50 +- 1.32  0.00 +- 0.00  0.15 +- 0.36   \n",
       "4  0.20 +- 0.51  3.60 +- 1.28  1.60 +- 2.20  0.35 +- 0.57  0.00 +- 0.00   \n",
       "5  1.55 +- 1.12  0.15 +- 0.36  0.70 +- 0.90  2.75 +- 2.70  0.75 +- 1.09   \n",
       "6  1.75 +- 1.58  0.75 +- 0.83  0.80 +- 1.08  0.00 +- 0.00  0.95 +- 1.02   \n",
       "7  0.05 +- 0.22  0.90 +- 1.79  0.65 +- 1.35  0.30 +- 0.56  1.15 +- 1.11   \n",
       "8  1.00 +- 0.95  0.95 +- 1.47  1.80 +- 1.83  2.25 +- 2.32  1.05 +- 1.02   \n",
       "9  0.30 +- 0.56  0.55 +- 1.24  0.35 +- 0.48  0.45 +- 0.74  3.60 +- 4.51   \n",
       "\n",
       "              5             6             7             8             9  \n",
       "0  1.05 +- 0.80  1.65 +- 1.74  0.10 +- 0.30  0.35 +- 0.57  0.25 +- 0.43  \n",
       "1  0.05 +- 0.22  0.55 +- 0.80  0.50 +- 0.81  0.45 +- 0.67  0.50 +- 0.92  \n",
       "2  0.45 +- 0.86  0.25 +- 0.43  1.85 +- 1.35  0.90 +- 1.41  0.00 +- 0.00  \n",
       "3  5.00 +- 5.18  0.05 +- 0.22  0.80 +- 0.98  2.50 +- 2.46  0.35 +- 0.48  \n",
       "4  0.40 +- 0.73  1.60 +- 1.74  0.70 +- 0.84  0.20 +- 0.51  3.05 +- 2.99  \n",
       "5  0.00 +- 0.00  2.00 +- 2.00  0.50 +- 0.50  1.30 +- 1.38  0.50 +- 0.74  \n",
       "6  0.90 +- 0.77  0.00 +- 0.00  0.00 +- 0.00  0.70 +- 0.78  0.05 +- 0.22  \n",
       "7  0.40 +- 1.11  0.00 +- 0.00  0.00 +- 0.00  1.05 +- 0.97  4.75 +- 9.16  \n",
       "8  2.10 +- 1.89  0.90 +- 1.14  0.90 +- 1.87  0.00 +- 0.00  1.15 +- 1.28  \n",
       "9  0.50 +- 0.74  0.00 +- 0.00  3.85 +- 4.45  0.40 +- 0.80  0.00 +- 0.00  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Might need to use pandas for it\n",
    "confusions_matrix = []\n",
    "for i in range(10):\n",
    "    confusions_i = []\n",
    "    for j in range(10):\n",
    "        confusions_ij = np.asarray([confusions[r][i,j] for r in range(runs)])\n",
    "        confusions_i.append(\"{0:.2f} +- {1:.2f}\".format(confusions_ij.mean(), np.std(confusions_ij)))\n",
    "    confusions_matrix.append(confusions_i)\n",
    "    \n",
    "df = pd.DataFrame(data=confusions_matrix)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4 - Hardest numbers to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x2160 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We only have to show 5, but let's show 10 for the purposes of seeingthat indeed the first 5 are the worst\n",
    "# WARNING: RE-RUN THIS BIT, these images are incorrect!\n",
    "indices = np.flip(np.argsort(mistakes_per_run))[:10]\n",
    "\n",
    "plt.figure(figsize=(30,30))\n",
    "\n",
    "k = 1\n",
    "for i in indices:\n",
    "    a1 = plt.subplot(1, 10, k)\n",
    "    pixels = np.array(x[i], dtype='uint8')\n",
    "    pixels = pixels.reshape((16, 16))\n",
    "    plt.title(\"Real: {0}\".format(y[i]))\n",
    "    a1.imshow(pixels, cmap='gray')\n",
    "    k+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q5 - Gaussian Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now doing run  20 / 20  for d= 7 .........\r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training set error rate</th>\n",
       "      <th>Test set error rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0000 +- 0.0001</td>\n",
       "      <td>0.0606 +- 0.0033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0000 +- 0.0000</td>\n",
       "      <td>0.0630 +- 0.0046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0000 +- 0.0000</td>\n",
       "      <td>0.0619 +- 0.0059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0000 +- 0.0000</td>\n",
       "      <td>0.0600 +- 0.0055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0000 +- 0.0000</td>\n",
       "      <td>0.0638 +- 0.0058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0000 +- 0.0000</td>\n",
       "      <td>0.0790 +- 0.0049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0000 +- 0.0001</td>\n",
       "      <td>0.0969 +- 0.0046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Training set error rate Test set error rate\n",
       "1        0.0000 +- 0.0001    0.0606 +- 0.0033\n",
       "2        0.0000 +- 0.0000    0.0630 +- 0.0046\n",
       "3        0.0000 +- 0.0000    0.0619 +- 0.0059\n",
       "4        0.0000 +- 0.0000    0.0600 +- 0.0055\n",
       "5        0.0000 +- 0.0000    0.0638 +- 0.0058\n",
       "6        0.0000 +- 0.0000    0.0790 +- 0.0049\n",
       "7        0.0000 +- 0.0001    0.0969 +- 0.0046"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runs = 20\n",
    "d_arr = np.arange(1,8)\n",
    "\n",
    "training_set_errors, test_set_errors = basic_results(d_arr, 'Gaussian', runs)\n",
    "means_std = construct_dataframe_error_rates(training_set_errors, test_set_errors)\n",
    "df = pd.DataFrame(data=means_std, index=d_arr, columns=['Training set error rate', 'Test set error rate'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Change the number of runs to 20!!!\n",
      "WARNING: Change the number of runs to 20!!!\n",
      "WARNING: Change the number of runs to 20!!!\n",
      "WARNING: Change the number of runs to 20!!!\n",
      "WARNING: Change the number of runs to 20!!!\n",
      "WARNING: Change the number of runs to 20!!!\n",
      "WARNING: Change the number of runs to 20!!!\n",
      "WARNING: Change the number of runs to 20!!!\n",
      "WARNING: Change the number of runs to 20!!!\n",
      "WARNING: Change the number of runs to 20!!!\n",
      "WARNING: Change the number of runs to 20!!!\n",
      "WARNING: Change the number of runs to 20!!!\n",
      "WARNING: Change the number of runs to 20!!!\n",
      "WARNING: Change the number of runs to 20!!!\n",
      "WARNING: Change the number of runs to 20!!!\n",
      "WARNING: Change the number of runs to 20!!!\n",
      "WARNING: Change the number of runs to 20!!!\n",
      "WARNING: Change the number of runs to 20!!!\n",
      "WARNING: Change the number of runs to 20!!!\n",
      "WARNING: Change the number of runs to 20!!!\n",
      "Mean d*:  1.05  with std:  1.16081867662439\n",
      "Mean test error:  0.4402956989247312  with std:  0.4217173757449448\n"
     ]
    }
   ],
   "source": [
    "#Cross Validation with Gaussian Kernel, find c_star\n",
    "runs = 20\n",
    "d_stars, test_errors, confusions, mistakes_per_run = cv_process(d_arr, runs, 'Gaussian', False)\n",
    "print(\"Mean d*: \", d_stars.mean(), \" with std: \", np.std(d_stars))\n",
    "print(\"Mean test error: \", test_errors.mean(), \" with std: \", np.std(test_errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q6 - Choose an alternative method to generalise k-classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q7 - Choose two more algorithms to compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One against rest approach\n",
    "#Problem: What is the hyperparameter to be tuned? C-value: C = 1/lambda, which is the regularization coefficient. \n",
    "#https://stackoverflow.com/questions/21816346/fine-tuning-parameters-in-logistic-regression\n",
    "#http://dataaspirant.com/2017/05/15/implement-multinomial-logistic-regression-python/\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X_train, X_test, y_train, y_test = allocate_training_test_sets(data,r =1/5)\n",
    "# Train multi-classification model with logistic regression\n",
    "lr = LogisticRegression(C=1,random_state=0, solver='newton-cg',multi_class='multinomial').fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Logistic regression Train Accuracy ::  0.9909922022048938\n",
      "Multinomial Logistic regression Test Accuracy ::  0.9451612903225807\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "#print (\"Logistic regression Train Accuracy :: \", metrics.accuracy_score(y_train, lr.predict(x_train)))\n",
    "#print (\"Logistic regression Test Accuracy :: \", metrics.accuracy_score(y_test, lr.predict(x_test)))\n",
    "print (\"Multinomial Logistic regression Train Accuracy :: \", metrics.accuracy_score(y_train, lr.predict(X_train)))\n",
    "print (\"Multinomial Logistic regression Test Accuracy :: \", metrics.accuracy_score(y_test, lr.predict(X_test)))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different ideas - LR uses probability theory, it'd be interest to compare with perceptron which is simply geometric. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One against one approach, or One against All approach? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Maybe logistic regression and SVM. \n",
    "from sklearn import svm\n",
    "clf = svm.SVC(gamma='scale')\n",
    "clf.fit(X_train, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Train Accuracy ::  0.9877655283678408\n",
      "SVM Test Accuracy ::  0.9747311827956989\n"
     ]
    }
   ],
   "source": [
    "print (\"SVM Train Accuracy :: \", metrics.accuracy_score(y_train, clf.predict(X_train)))\n",
    "print (\"SVM Test Accuracy :: \", metrics.accuracy_score(y_test, clf.predict(X_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
